
@article{yang_machine_2023,
	title = {Machine learning to support citizen science in urban environmental management},
	volume = {9},
	issn = {24058440},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2405844023098961},
	doi = {10.1016/j.heliyon.2023.e22688},
	abstract = {Machine learning ({ML}) and citizen science ({CS}) are increasingly prevalent and rapidly evolving approaches to studying and managing environmental challenges. Municipal and other governance actors can benefit from technology advances in {ML} and public engagement benefits of {CS} but must also address validity and other quality assurance concerns in their application to particular management contexts. In this article, we take up the pervasive challenge of urban litter to demonstrate how {ML} can support {CS} by providing quality assurance in the regulatory context of California’s stormwater program. We gave quantitative {CS}-collected data to five {ML} models to compare their predictions of a qualitative, site-specific, multiclass “Litter Index” score, an important regulatory metric typically only assessed by trained experts. {XGBoost} had the best outcome, with scores of 0.98 for accuracy, precision, recall and F-1. These strong results show that {ML} can provide a reliable complement to {CS} assessments and increase quality assurance in a regulatory context. To date, {ML} and {CS} have each contributed to litter management in novel ways and we find that their integration can provide important synergies with additional applications in other environmental management domains.},
	pages = {e22688},
	number = {12},
	journaltitle = {Heliyon},
	shortjournal = {Heliyon},
	author = {Yang, Emily J. and Fulton, Julian and Swarnaraja, Swabinash and Carson, Cecile},
	urldate = {2025-01-15},
	date = {2023-12},
	langid = {english},
	file = {PDF:/home/andri/Zotero/storage/CP92TXXJ/Yang et al. - 2023 - Machine learning to support citizen science in urban environmental management.pdf:application/pdf},
}

@report{bonn_grunbuch_2016,
	location = {Berlin},
	title = {Grünbuch Citizen Science Strategie 2020 für Deutschland},
	abstract = {Das vorliegende Grünbuch für eine Citizen Science Strategie 2020 stellt die Ziele, Potenziale und Herausforderungen von Citizen Science in Deutschland dar und zeigt Handlungsoptionen für die Entwicklung einer nationalen Strategie zur Einbindung von Bürgerinnen und Bürgern in die Wissenschaft auf. Dabei wird der Fokus auf drei Handlungsfelder gelegt: Die Stärkung etablierter Strukturen, die Neuschaffung von Rahmenbedingungen und die weitere Integration von Cititzen Science in bestehende Konzepte durch verschiedene Maßnahmen. Außerdem werden im Grünbuch vor allem auch die Ziele und Möglichkeiten ebenso wie eine Vision für die Rolle von Citizen Science im Jahr 2020, unter anderem in Form von zehn Leitbildern, definiert. Im Vordergrund stehen auch hier die breite Etablierung, Anerkennung und Einbeziehung von Citizen Science in gesellschaftsrelevante Kontexte.},
	pages = {40},
	institution = {Projekt "Bürger schaffen Wissen - Wissen schafft Bürger" ({GEWISS})},
	author = {Bonn, Aletta and Richter, Anett and Vohland, Kathrin and Pettibone, Lisa and Brandt, Miriam and Feldmann, Reinart and Goebel, Claudia and Grefe, Christiane and Hecker, Susanne and Hennen, Leonhard and Hofer, Heribert and Kiefer, Sarah and Klotz, Stefan and Kluttig, Thekla and Krause, Jens and Küsel, Kirsten and Liedtke, Christin and Mahla, Anika and Neumeier, Veronika and Premke-Kraus, Matthias and Rillig, Matthias C. and Röller, Oliver and Schäffler, Livia and Schmalzbauer, Bettina and Schneidewind, Uwe and Schumann, Anke and Settele, Josef and Tochtermann, Klaus and Tockner, Klement and Vogel, Johannes},
	date = {2016},
	langid = {german},
}

@collection{vohland_science_2021,
	location = {Cham},
	title = {The Science of Citizen Science},
	rights = {https://creativecommons.org/licenses/by/4.0},
	isbn = {978-3-030-58277-7 978-3-030-58278-4},
	url = {https://link.springer.com/10.1007/978-3-030-58278-4},
	publisher = {Springer International Publishing},
	editor = {Vohland, Katrin and Land-Zandstra, Anne and Ceccaroni, Luigi and Lemmens, Rob and Perelló, Josep and Ponti, Marisa and Samson, Roeland and Wagenknecht, Katherin},
	urldate = {2025-01-15},
	date = {2021},
	langid = {english},
	doi = {10.1007/978-3-030-58278-4},
	file = {PDF:/home/andri/Zotero/storage/6VL7ZBCS/Vohland et al. - 2021 - The Science of Citizen Science.pdf:application/pdf},
}

@article{wullschleger_data_nodate,
	title = {Data Acquisition for Urban Biodiversity Monitoring},
	abstract = {Biodiversity is important and must be preserved because, not least, human existence depends on it. If it were to disappear, there would be no food, no clean water and the entire human ecosystem would collapse.},
	author = {Wullschleger, Timeo},
	langid = {german},
	file = {PDF:/home/andri/Zotero/storage/8CK53BUD/Wullschleger - Data Acquisition for Urban Biodiversity Monitoring.pdf:application/pdf},
}

@article{wullschleger_automated_nodate,
	title = {Automated Analysis for Urban Biodiversity Monitoring},
	abstract = {Human existence depends on biodiversity. Pollinators play a special role because plant reproduction depends on them. Due to human actions and environmental influences, the population of pollinators varies greatly around the world. Since they play a key role in biodiversity, monitoring pollinators is important to detect changes early on.},
	author = {Wullschleger, Timeo},
	langid = {german},
	file = {PDF:/home/andri/Zotero/storage/7SVMEEGM/Wullschleger - Automated Analysis for Urban Biodiversity Monitoring.pdf:application/pdf},
}

@online{bdm_verlassliche_nodate,
	title = {Verlässliche Daten über unsere Lebens­grundlage},
	url = {https://www.biodiversitymonitoring.ch/index.php/de/},
	titleaddon = {biodiversitymonitoring.ch},
	author = {bdm},
	urldate = {2025-01-15},
	file = {Startseite:/home/andri/Zotero/storage/HJUMMNHF/de.html:text/html},
}

@online{noauthor_tensorflow_nodate,
	title = {{TensorFlow}},
	url = {https://www.tensorflow.org/},
	urldate = {2025-01-16},
}

@online{noauthor_pytorch_nodate,
	title = {{PyTorch}},
	url = {https://pytorch.org/},
	urldate = {2025-01-16},
	file = {PyTorch:/home/andri/Zotero/storage/VWY763Y5/pytorch.org.html:text/html},
}

@online{noauthor_onnx_nodate,
	title = {{ONNX} {\textbar} Home},
	url = {https://onnx.ai/},
	urldate = {2025-01-16},
}

@online{noauthor_ki-edge-prozessoren_nodate,
	title = {{KI}-Edge-Prozessoren für Höchstleistung - Hailo {KI} Chip},
	url = {https://hailo.ai/de/},
	abstract = {Hailo bietet bahnbrechende {KI}-Beschleuniger und Vision-Prozessoren an, die speziell für leistungsstarke, eingebettete Deep-Learning-Anwendungen auf Edge-Geräten entwickelt werden.},
	titleaddon = {Hailo},
	urldate = {2025-01-16},
	langid = {german},
	file = {Snapshot:/home/andri/Zotero/storage/RYNR44IY/de.html:text/html},
}

@online{ltd_raspberry_nodate,
	title = {Raspberry Pi},
	url = {https://www.raspberrypi.com/},
	abstract = {From industries large and small, to the kitchen table tinkerer, to the classroom coder, we make computing accessible and affordable for everybody.},
	titleaddon = {Raspberry Pi},
	author = {Ltd, Raspberry Pi},
	urldate = {2025-01-16},
	langid = {british},
	file = {Snapshot:/home/andri/Zotero/storage/5ZQDNRND/www.raspberrypi.com.html:text/html},
}

@online{ltd_buy_nodate,
	title = {Buy a Raspberry Pi {AI} Camera},
	url = {https://www.raspberrypi.com/products/ai-camera/},
	abstract = {The Raspberry Pi {AI} Camera takes advantage of Sony’s {IMX}500 Intelligent Vision Sensor to help you create impressive vision {AI} applications and neural network models.},
	titleaddon = {Raspberry Pi},
	author = {Ltd, Raspberry Pi},
	urldate = {2025-01-16},
	langid = {british},
	file = {Snapshot:/home/andri/Zotero/storage/4WUVAEYV/ai-camera.html:text/html},
}

@online{ultralytics_home_nodate,
	title = {Home},
	url = {https://docs.ultralytics.com/},
	abstract = {Discover Ultralytics {YOLO} - the latest in real-time object detection and image segmentation. Learn its features and maximize its potential in your projects.},
	author = {Ultralytics},
	urldate = {2025-01-16},
	langid = {english},
	file = {Snapshot:/home/andri/Zotero/storage/I6C3MFM7/docs.ultralytics.com.html:text/html},
}

@online{noauthor_openai_nodate,
	title = {{OpenAI} standardizes on {PyTorch}},
	url = {https://openai.com/index/openai-pytorch/},
	abstract = {We are standardizing {OpenAI}’s deep learning framework on {PyTorch}.},
	urldate = {2025-01-16},
	langid = {american},
	file = {Snapshot:/home/andri/Zotero/storage/29K2YEAS/openai-pytorch.html:text/html},
}

@software{ni_ncnn_2017,
	title = {ncnn},
	url = {https://github.com/Tencent/ncnn},
	abstract = {ncnn is a high-performance neural network inference framework optimized for the mobile platform},
	author = {Ni, Hui and {The ncnn contributors}},
	urldate = {2025-01-16},
	date = {2017-06},
	note = {original-date: 2017-06-30T10:55:37Z},
	file = {PDF:/home/andri/Zotero/storage/NP8TBIA3/Ni and The ncnn contributors - 2017 - ncnn.pdf:application/pdf},
}

@online{noauthor_products_nodate,
	title = {Products},
	url = {https://coral.ai/products/#prototyping-products},
	abstract = {Helping you bring local {AI} to applications from prototype to production},
	titleaddon = {Coral},
	urldate = {2025-01-16},
	langid = {english},
	file = {Snapshot:/home/andri/Zotero/storage/QQAIMAME/products.html:text/html},
}

@online{ltd_buy_nodate-1,
	title = {Buy a Raspberry Pi 5},
	url = {https://www.raspberrypi.com/products/raspberry-pi-5/},
	abstract = {The everything computer. Optimised.},
	titleaddon = {Raspberry Pi},
	author = {Ltd, Raspberry Pi},
	urldate = {2025-01-16},
	langid = {british},
}

@online{ltd_buy_nodate-2,
	title = {Buy a Raspberry Pi 4 Model B},
	url = {https://www.raspberrypi.com/products/raspberry-pi-4-model-b/},
	abstract = {Your tiny, dual-display, desktop computer
…and robot brains, smart home hub, media centre, networked {AI} core, factory controller, and much more.},
	titleaddon = {Raspberry Pi},
	author = {Ltd, Raspberry Pi},
	urldate = {2025-01-16},
	langid = {british},
	file = {Snapshot:/home/andri/Zotero/storage/AWNK7UWY/raspberry-pi-4-model-b.html:text/html},
}

@software{tapuhi_hailo_2021,
	title = {Hailo Model Zoo},
	rights = {{MIT}},
	url = {https://github.com/hailo-ai/hailo_model_zoo},
	abstract = {The Hailo Model Zoo includes pre-trained models and a full building and evaluation environment},
	author = {Tapuhi, Tamir and Gluska, Shachar and Klinger, Amit and Dharan, Nadiv and Sholev, Omer and Zelig, Yuval and Vosco, Niv},
	urldate = {2025-01-16},
	date = {2021-07},
	note = {original-date: 2021-07-13T18:31:25Z},
}

@software{awild_andriwildip7-ml-model-eval_2024,
	title = {andriwild/ip7-ml-model-eval},
	url = {https://github.com/andriwild/ip7-ml-model-eval},
	author = {awild},
	urldate = {2025-01-16},
	date = {2024-11-20},
	note = {original-date: 2024-10-08T11:47:18Z},
}

@software{awild_andriwildip7-ai-cam_2025,
	title = {andriwild/ip7-ai-cam},
	url = {https://github.com/andriwild/ip7-ai-cam},
	author = {awild},
	urldate = {2025-01-16},
	date = {2025-01-15},
	note = {original-date: 2024-12-05T12:19:42Z},
}

@online{noauthor_ai_nodate,
	title = {{AI} Kit - Raspberry Pi Documentation},
	url = {https://www.raspberrypi.com/documentation/accessories/ai-kit.html},
	abstract = {The official documentation for Raspberry Pi computers and microcontrollers},
	urldate = {2025-01-20},
	langid = {english},
	file = {Snapshot:/home/andri/Zotero/storage/X26Y5CPN/ai-kit.html:text/html},
}

@online{noauthor_ai_nodate-1,
	title = {{AI} Camera - Raspberry Pi Documentation},
	url = {https://www.raspberrypi.com/documentation/accessories/ai-camera.html},
	abstract = {The official documentation for Raspberry Pi computers and microcontrollers},
	urldate = {2025-01-20},
	langid = {english},
	file = {Snapshot:/home/andri/Zotero/storage/NZRE6Z95/ai-camera.html:text/html},
}

@online{noauthor_pineboards_nodate,
	title = {Pineboards Hat {AI}! Dual, Edge Coral {TPU} für Raspberry Pi 5, Bundle - kaufen bei {BerryBase}},
	url = {https://www.berrybase.ch/pineboards-hat-ai-dual-edge-coral-tpu-fuer-raspberry-pi-5-bundle},
	abstract = {Das Hat {AI}! Dual ist die erste Google Coral Dual Edge {TPU} Integration im Raspberry Pi 5 Ökosystem. Dieses Bundle beinhaltet sow...},
	titleaddon = {{BerryBase} - The Maker Shop},
	urldate = {2025-01-20},
	langid = {german},
	file = {Snapshot:/home/andri/Zotero/storage/EA9XK6C3/pineboards-hat-ai-dual-edge-coral-tpu-fuer-raspberry-pi-5-bundle.html:text/html},
}

@online{noauthor_coral_nodate,
	title = {Coral {USB} Accelerator},
	url = {https://www.pi-shop.ch/coral-usb-accelerator},
	abstract = {A {USB} accessory that brings machine learning inferencing to existing systems. Works with Raspberry Pi and other Linux systems.},
	titleaddon = {Pi-Shop.ch},
	urldate = {2025-01-20},
	langid = {german},
	file = {Snapshot:/home/andri/Zotero/storage/HUNC6B2T/coral-usb-accelerator.html:text/html},
}

@online{noauthor_pineboards_nodate-1,
	title = {Pineboards Hat {AI}!, Coral Edge {TPU} Erweiterung für Raspberry Pi 5, Bundle - kaufen bei {BerryBase}},
	url = {https://www.berrybase.ch/pineboards-hat-ai-coral-edge-tpu-erweiterung-fuer-raspberry-pi-5-bundle},
	abstract = {Das Hat Ai! Coral Edge {TPU} Bundle ermöglicht die Integration der Google Coral Edge {TPU} in Raspberry Pi 5 Projekte. Diese neue V...},
	titleaddon = {{BerryBase} - The Maker Shop},
	urldate = {2025-01-20},
	langid = {german},
	file = {PDF:/home/andri/Zotero/storage/HA36KMV3/Pineboards Hat AI!, Coral Edge TPU Erweiterung für Raspberry Pi 5, Bundle - kaufen bei BerryBase.pdf:application/pdf;Snapshot:/home/andri/Zotero/storage/BEVSHBAS/pineboards-hat-ai-coral-edge-tpu-erweiterung-fuer-raspberry-pi-5-bundle.html:text/html},
}

@online{noauthor_raspberry_nodate,
	title = {Raspberry Pi {AI} {HAT}+ (26T)},
	url = {https://www.pi-shop.ch/raspberry-pi-ai-hat-26t},
	abstract = {Raspberry Pi {AI} {HAT}+ (26T)},
	titleaddon = {Pi-Shop.ch},
	urldate = {2025-01-20},
	langid = {german},
	file = {Snapshot:/home/andri/Zotero/storage/I5C6MVU5/raspberry-pi-ai-hat-26t.html:text/html},
}

@online{noauthor_raspberry_nodate-1,
	title = {Raspberry Pi {AI} {HAT}+ (13T)},
	url = {https://www.pi-shop.ch/raspberry-pi-ai-hat-13t},
	abstract = {Raspberry Pi {AI} {HAT}+ (13T)},
	titleaddon = {Pi-Shop.ch},
	urldate = {2025-01-20},
	langid = {german},
	file = {Snapshot:/home/andri/Zotero/storage/HJD8D9CL/raspberry-pi-ai-hat-13t.html:text/html},
}

@online{noauthor_raspberry_nodate-2,
	title = {Raspberry Pi {AI} Camera - kaufen bei {BerryBase}},
	url = {https://www.berrybase.ch/raspberry-pi-ai-camera},
	abstract = {Das Raspberry Pi {AI} Kamera Modul ist ein kompaktes Kameramodul von Raspberry Pi, basierend auf dem Sony {IMX}500 Intelligent Visi...},
	titleaddon = {{BerryBase} - The Maker Shop},
	urldate = {2025-01-20},
	langid = {german},
	file = {Snapshot:/home/andri/Zotero/storage/WBPPZAIL/raspberry-pi-ai-camera.html:text/html},
}

@online{noauthor_raspberry_nodate-3,
	title = {Raspberry Pi 4 Model B - 8GB},
	url = {https://www.pi-shop.ch/raspberry-pi-4-model-b-8gb},
	abstract = {Raspberry Pi 4 Model B - 8GB},
	titleaddon = {Pi-Shop.ch},
	urldate = {2025-01-20},
	langid = {german},
	file = {Snapshot:/home/andri/Zotero/storage/K3M97J22/raspberry-pi-4-model-b-8gb.html:text/html},
}

@online{noauthor_beagley-ai_nodate,
	title = {{BeagleY}®-{AI}},
	url = {https://www.seeedstudio.com/BeagleYr-AI-beagleboard-orgr-4-TOPS-AI-Acceleration-powered-by-TI-AM67A.html},
	abstract = {{BeagleY}®-{AI} is a high-performance single board computer powered by the Texas Instruments {AM}67A {AI} vision processor, delivering up to 4 {TOPS} of deep learning capability. Ideal for robotics, automation, and intelligent vision projects, it features extensive connectivity options and a 40-pin header for easy prototyping. Perfect for enthusiasts and professionals alike, {BeagleY}®-{AI} combines power and versatility in a compact, open-source design. Check more Beaglebone Hardware. 
Our {US} warehouse is now fully stocked. Buy 2, Get Free Shipping!},
	urldate = {2025-01-20},
	langid = {english},
	file = {Snapshot:/home/andri/Zotero/storage/RM9IE6BU/BeagleYr-AI-beagleboard-orgr-4-TOPS-AI-Acceleration-powered-by-TI-AM67A.html:text/html},
}

@online{noauthor_raspberry_nodate-4,
	title = {Raspberry Pi 5 Model B 8GB},
	url = {https://www.pi-shop.ch/raspberry-pi-5-8-gb},
	abstract = {Raspberry Pi 5 Model B, 8 {GB}},
	titleaddon = {Pi-Shop.ch},
	urldate = {2025-01-20},
	langid = {german},
	file = {Snapshot:/home/andri/Zotero/storage/27UA9W4L/raspberry-pi-5-8-gb.html:text/html},
}

@software{noauthor_sonymodel_optimization_2025,
	title = {sony/model\_optimization},
	rights = {Apache-2.0},
	url = {https://github.com/sony/model_optimization},
	abstract = {Model Compression Toolkit ({MCT}) is an open source project for neural network model optimization under efficient, constrained hardware. This project provides researchers, developers, and engineers advanced quantization and compression tools for deploying state-of-the-art neural networks.},
	publisher = {Sony},
	urldate = {2025-01-20},
	date = {2025-01-16},
	note = {original-date: 2021-06-21T03:28:09Z},
	keywords = {deep-learning, deep-neural-networks, edge-ai, machine-learning, network-compression, network-quantization, neural-network, optimizer, ptq, pytorch, qat, quantization, tensorflow},
}

@online{ultralytics_yolov5_nodate,
	title = {{YOLOv}5},
	url = {https://docs.ultralytics.com/models/yolov5},
	abstract = {Explore {YOLOv}5u, an advanced object detection model with optimized accuracy-speed tradeoff, featuring anchor-free Ultralytics head and various pre-trained models.},
	author = {Ultralytics},
	urldate = {2025-01-23},
	langid = {english},
	file = {Snapshot:/home/andri/Zotero/storage/YRR9NMZF/yolov5.html:text/html},
}

@online{noauthor_tpu_nodate,
	title = {{TPU} (Tensor Processing Unit)},
	url = {https://www.ultralytics.com/glossary/tpu-tensor-processing-unit},
	abstract = {Discover how Google's {TPUs} accelerate machine learning with unmatched speed, energy efficiency, and optimized {TensorFlow} performance.},
	urldate = {2025-01-23},
	langid = {english},
	file = {Snapshot:/home/andri/Zotero/storage/LXA9LW3I/tpu-tensor-processing-unit.html:text/html},
}

@online{noauthor_what_2024,
	title = {What is a Neural Processing Unit ({NPU})? {\textbar} {IBM}},
	url = {https://www.ibm.com/think/topics/neural-processing-unit},
	shorttitle = {What is a Neural Processing Unit ({NPU})?},
	abstract = {A neural processing unit ({NPU}) is a specialized computer microprocessor designed to mimic the processing function of the human brain.},
	urldate = {2025-01-23},
	date = {2024-09-27},
	langid = {english},
}

@online{noauthor_npu_2024,
	title = {{NPU} vs {GPU}: What's the Difference? {\textbar} {IBM}},
	url = {https://www.ibm.com/think/topics/npu-vs-gpu},
	shorttitle = {{NPU} vs {GPU}},
	abstract = {{NPUs} and {GPUs} complement a system’s main {CPU}. The main differences between the two come down to chip architecture and processing capabilities.},
	urldate = {2025-01-23},
	date = {2024-10-10},
	langid = {english},
}

@online{noauthor_fuhrende_nodate,
	title = {Das führende {KI}-Chip-Unternehmen für Edge-Geräte},
	url = {https://hailo.ai/de/company-overview/},
	abstract = {Als führendes {KI}-Chip-Unternehmen schließt Hailo mit seiner Smart-Edge-Lösung die Lücke zwischen bestehenden und zukünftigen {KI}-Technologien und der für den Betrieb dieser Anwendungen erforderlichen Rechenkapazität.},
	titleaddon = {Hailo},
	urldate = {2025-01-27},
	langid = {german},
	file = {Snapshot:/home/andri/Zotero/storage/9BCKX64P/company-overview.html:text/html},
}

@online{ultralytics_yolov5_nodate-1,
	title = {{YOLOv}5 vs {YOLOv}8: A Detailed Comparison for Object Detection},
	url = {https://docs.ultralytics.com/compare/yolov5-vs-yolov8},
	shorttitle = {{YOLOv}5 vs {YOLOv}8},
	abstract = {Discover key differences between {YOLOv}5 and {YOLOv}8. Compare speed, accuracy, and versatility to choose the right object detection model for your project.},
	author = {Ultralytics},
	urldate = {2025-01-29},
	langid = {english},
	file = {Snapshot:/home/andri/Zotero/storage/WI3ZMZWF/yolov5-vs-yolov8.html:text/html},
}

@online{noauthor_software_nodate,
	title = {Software Suite for {AI} Applications \& Deep Learning {\textbar} Hailo {AI}},
	url = {https://hailo.ai/products/hailo-software/hailo-ai-software-suite/},
	abstract = {Software for {AI} applications \& deep learning model deployment. {ML} frameworks integration \& x86, {ARM}, Hailo {AI} processors optimized.},
	titleaddon = {Hailo},
	urldate = {2025-01-29},
	langid = {american},
	file = {Snapshot:/home/andri/Zotero/storage/BQXBJUAJ/hailo-ai-software-suite.html:text/html},
}

@online{noauthor_hailo_model_zoohailo_model_zoocfg_nodate,
	title = {hailo\_model\_zoo/hailo\_model\_zoo/cfg at master · hailo-ai/hailo\_model\_zoo},
	url = {https://github.com/hailo-ai/hailo_model_zoo/tree/master/hailo_model_zoo/cfg},
	urldate = {2025-01-29},
	file = {hailo_model_zoo/hailo_model_zoo/cfg at master · hailo-ai/hailo_model_zoo:/home/andri/Zotero/storage/JSDXA4TI/cfg.html:text/html;PDF:/home/andri/Zotero/storage/4Y8AQYIE/hailo_model_zoohailo_model_zoocfg at master · hailo-aihailo_model_zoo.pdf:application/pdf},
}

@online{noauthor_imx500_nodate,
	title = {{IMX}500 Converter {\textbar} Sony Semiconductor Solutions Group},
	url = {https://developer.aitrios.sony-semicon.com/en/raspberrypi-ai-camera/documentation/imx500-converter?version=3.14.3&progLang=},
	urldate = {2025-01-29},
	file = {IMX500 Converter | Sony Semiconductor Solutions Group:/home/andri/Zotero/storage/R6VUIY5U/imx500-converter.html:text/html},
}

@online{noauthor_recamera_nodate,
	title = {{reCamera}},
	url = {https://www.seeedstudio.com/recamera?srsltid=AfmBOopbSxSK-BPmVHDRVm0pGJWa_aRpSmQuWH0XmIjh2ARMrHknYQyG},
	abstract = {Define the Most Advanced {AI} Camera {reCamera} is a versatile combination of a processor and},
	urldate = {2025-02-01},
	langid = {english},
	file = {Snapshot:/home/andri/Zotero/storage/KHGQIFLQ/recamera.html:text/html},
}

@online{noauthor_ecoeye_nodate,
	title = {{EcoEye}: {OpenMV} H7+ Camera with Sensor Integration for Environmental Monitoring},
	url = {https://www.seeedstudio.com/EcoEye-Embedded-Vision-Camera-p-5843.html},
	shorttitle = {{EcoEye}},
	abstract = {{EcoEye} is a camera with onboard machine vision capabilities encased in a portable and water resistance housing designed for remote deployments. Based on the {openMV} H7 Plus Cam, it is easy to set up and flexible to numerous applications. The internal power management and control system enables long-term operation and allows the integration of solar panels, countless sensors, and other external devices. The camera is thoroughly field tested, and the results are published in a scientific article.},
	urldate = {2025-02-01},
	langid = {english},
	file = {Snapshot:/home/andri/Zotero/storage/YHIAYAIR/EcoEye-Embedded-Vision-Camera-p-5843.html:text/html},
}

@online{ultralytics_onnx_nodate,
	title = {{ONNX}},
	url = {https://docs.ultralytics.com/integrations/onnx},
	abstract = {Learn how to export {YOLO}11 models to {ONNX} format for flexible deployment across various platforms with enhanced performance.},
	author = {Ultralytics},
	urldate = {2025-02-02},
	langid = {english},
	file = {Snapshot:/home/andri/Zotero/storage/38ISZE3Y/onnx.html:text/html},
}

@online{noauthor_ip7-ml-model-evaldashboard_nodate,
	title = {ip7-ml-model-eval/dashboard at main · andriwild/ip7-ml-model-eval},
	url = {https://github.com/andriwild/ip7-ml-model-eval/tree/main/dashboard},
	urldate = {2025-02-02},
	file = {ip7-ml-model-eval/dashboard at main · andriwild/ip7-ml-model-eval:/home/andri/Zotero/storage/H7EWGGAB/dashboard.html:text/html},
}

@software{jocher_ultralytics_2023,
	title = {Ultralytics {YOLOv}8},
	url = {https://github.com/ultralytics/ultralytics},
	version = {8.0.0},
	author = {Jocher, Glenn and Chaurasia, Ayush and Qiu, Jing},
	date = {2023},
}

@online{noauthor_sparsification_nodate,
	title = {Sparsification: Compressing Neural Networks {\textbar} Neural Magic Documentation},
	url = {https://docs.neuralmagic.com/guides/sparsification/},
	shorttitle = {Sparsification},
	abstract = {A comprehensive overview of sparsification techniques used to create smaller, faster, and more energy-efficient neural networks while maintaining accuracy.},
	urldate = {2025-02-04},
	langid = {english},
	file = {Snapshot:/home/andri/Zotero/storage/AUEQHJC6/sparsification.html:text/html},
}

@article{deng_edge_2020,
	title = {Edge Intelligence: The Confluence of Edge Computing and Artificial Intelligence},
	volume = {7},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {2327-4662, 2372-2541},
	url = {https://ieeexplore.ieee.org/document/9052677/},
	doi = {10.1109/JIOT.2020.2984887},
	shorttitle = {Edge Intelligence},
	abstract = {Along with the rapid developments in communication technologies and the surge in the use of mobile devices, a brand-new computation paradigm, edge computing, is surging in popularity. Meanwhile, the artiﬁcial intelligence ({AI}) applications are thriving with the breakthroughs in deep learning and the many improvements in hardware architectures. Billions of data bytes, generated at the network edge, put massive demands on data processing and structural optimization. Thus, there exists a strong demand to integrate edge computing and {AI}, which gives birth to edge intelligence. In this article, we divide edge intelligence into {AI} for edge (intelligence-enabled edge computing) and {AI} on edge (artiﬁcial intelligence on edge). The former focuses on providing more optimal solutions to key problems in edge computing with the help of popular and effective {AI} technologies while the latter studies how to carry out the entire process of building {AI} models, i.e., model training and inference, on the edge. This article provides insights into this new interdisciplinary ﬁeld from a broader perspective. It discusses the core concepts and the research roadmap, which should provide the necessary background for potential future research initiatives in edge intelligence.},
	pages = {7457--7469},
	number = {8},
	journaltitle = {{IEEE} Internet of Things Journal},
	shortjournal = {{IEEE} Internet Things J.},
	author = {Deng, Shuiguang and Zhao, Hailiang and Fang, Weijia and Yin, Jianwei and Dustdar, Schahram and Zomaya, Albert Y.},
	urldate = {2025-02-04},
	date = {2020-08},
	langid = {english},
	file = {PDF:/home/andri/Zotero/storage/55GBEABR/Deng et al. - 2020 - Edge Intelligence The Confluence of Edge Computing and Artificial Intelligence.pdf:application/pdf},
}

@misc{hussain_yolov5_2024,
	title = {{YOLOv}5, {YOLOv}8 and {YOLOv}10: The Go-To Detectors for Real-time Vision},
	url = {http://arxiv.org/abs/2407.02988},
	doi = {10.48550/arXiv.2407.02988},
	shorttitle = {{YOLOv}5, {YOLOv}8 and {YOLOv}10},
	abstract = {This paper presents a comprehensive review of the evolution of the {YOLO} (You Only Look Once) object detection algorithm, focusing on {YOLOv}5, {YOLOv}8, and {YOLOv}10. We analyze the architectural advancements, performance improvements, and suitability for edge deployment across these versions. {YOLOv}5 introduced signiﬁcant innovations such as the {CSPDarknet} backbone and Mosaic Augmentation, balancing speed and accuracy. {YOLOv}8 built upon this foundation with enhanced feature extraction and anchor-free detection, improving versatility and performance. {YOLOv}10 represents a leap forward with {NMS}-free training, spatial-channel decoupled downsampling, and largekernel convolutions, achieving state-of-the-art performance with reduced computational overhead. Our ﬁndings highlight the progressive enhancements in accuracy, efﬁciency, and real-time performance, particularly emphasizing their applicability in resource-constrained environments. This review provides insights into the trade-offs between model complexity and detection accuracy, offering guidance for selecting the most appropriate {YOLO} version for speciﬁc edge computing applications.},
	number = {{arXiv}:2407.02988},
	publisher = {{arXiv}},
	author = {Hussain, Muhammad},
	urldate = {2025-02-04},
	date = {2024-07-03},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2407.02988 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {PDF:/home/andri/Zotero/storage/EH6JW7CT/Hussain - 2024 - YOLOv5, YOLOv8 and YOLOv10 The Go-To Detectors for Real-time Vision.pdf:application/pdf},
}

@misc{lin_microsoft_2015,
	title = {Microsoft {COCO}: Common Objects in Context},
	url = {https://arxiv.org/abs/1405.0312},
	author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Bourdev, Lubomir and Girshick, Ross and Hays, James and Perona, Pietro and Ramanan, Deva and Zitnick, C. Lawrence and Dollár, Piotr},
	date = {2015},
	note = {\_eprint: 1405.0312},
}

@online{noauthor_b3_nodate,
	title = {B3 - Bienen, Baumscheiben und Bestäubung},
	url = {https://www.citizenscience.uzh.ch/de/projekte/b3.html},
	urldate = {2025-02-07},
	langid = {german},
	file = {Snapshot:/home/andri/Zotero/storage/AVZFCLYI/b3.html:text/html},
}

@online{noauthor_vorhaben_nodate,
	title = {Vorhaben - Schweiz forscht},
	url = {https://www.schweizforscht.ch/projekte},
	abstract = {Du interessierst dich für Wissenschaft in der Schweiz, an der du selbst mitforschen kannst? Dann bist du auf Schweiz forscht genau richtig. Schau dir unsere aktuellen Projekte an. Egal ob du dich für Tiere, Pflanzen, Dialekte oder Gesundheit interessierst – es ist für alle ein passendes Projekt dabe...},
	urldate = {2025-02-07},
	langid = {german},
}

@online{noauthor_netron_nodate,
	title = {Netron},
	url = {https://netron.app/},
	urldate = {2025-02-07},
	file = {Netron:/home/andri/Zotero/storage/UVGVDDG8/netron.app.html:text/html},
}

@software{awild_andriwildip7-edge-ml-cam_2025,
	title = {andriwild/ip7-edge-ml-cam},
	rights = {{AGPL}-3.0},
	url = {https://github.com/andriwild/ip7-edge-ml-cam},
	author = {awild},
	urldate = {2025-02-07},
	date = {2025-02-07},
	note = {original-date: 2024-12-05T12:19:42Z},
}
